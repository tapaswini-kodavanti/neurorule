{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43d98b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30326553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights reloaded successfully.\n",
      "Test Accuracy: 97.22%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "data = datasets.load_wine()\n",
    "path = \"wine_mlp_weights.pth\"\n",
    "\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "targets = data.target\n",
    "input_dim = df.shape[1]\n",
    "num_classes = len(np.unique(targets))\n",
    "\n",
    "# Ready data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, targets, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # \"fit\" learns the mean/variance of each feature\n",
    "X_test = scaler.transform(X_test)  # fit isn't necessary because the scaler already learned the features\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "# Run model\n",
    "loaded_model = MLP(input_dim, num_classes)\n",
    "loaded_model.load_state_dict(torch.load(path))\n",
    "loaded_model.eval()\n",
    "print(\"Model weights reloaded successfully.\")\n",
    "\n",
    "predictions = loaded_model(X_test)\n",
    "_, predicted_classes = torch.max(predictions, 1)\n",
    "accuracy = (predicted_classes == y_test).float().mean()\n",
    "print(f\"Test Accuracy: {accuracy.item()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0446d052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bounds(X_df, numeric_cols, low_pct=1.0, high_pct=99.0, gamma=0.1):\n",
    "    # X_df: pandas DataFrame of training data (raw/unscaled)\n",
    "    mins = X_df[numeric_cols].quantile(low_pct/100.0).values\n",
    "    maxs = X_df[numeric_cols].quantile(high_pct/100.0).values\n",
    "    spans = maxs - mins\n",
    "    # avoid zero spans\n",
    "    spans[spans == 0] = 1e-6\n",
    "    low = mins - gamma * spans\n",
    "    high = maxs + gamma * spans\n",
    "    return low, high\n",
    "\n",
    "def synthesize_extrapolated(X_df, numeric_cols, categorical_cols,\n",
    "                            n_samples=5000, gamma=0.1, low_pct=1.0, high_pct=99.0,\n",
    "                            random_state=None):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    low, high = compute_bounds(X_df, numeric_cols, low_pct=low_pct, high_pct=high_pct, gamma=gamma)\n",
    "    n_num = len(numeric_cols)\n",
    "    Xs_num = rng.uniform(low=low, high=high, size=(n_samples, n_num))\n",
    "\n",
    "    # categorical: sample by empirical frequencies\n",
    "    Xs_cat = {}\n",
    "    for c in categorical_cols:\n",
    "        vals, counts = np.unique(X_df[c].values, return_counts=True)\n",
    "        probs = counts / counts.sum()\n",
    "        picks = rng.choice(len(vals), size=n_samples, p=probs)\n",
    "        Xs_cat[c] = vals[picks]\n",
    "\n",
    "    # assemble DataFrame\n",
    "    df_num = pd.DataFrame(Xs_num, columns=numeric_cols)\n",
    "    df_cat = pd.DataFrame(Xs_cat)\n",
    "    Xs = pd.concat([df_num, df_cat.reset_index(drop=True)], axis=1)[list(numeric_cols) + list(categorical_cols)]\n",
    "    return Xs\n",
    "\n",
    "def run_through_model(X, model):\n",
    "    X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        scaler = StandardScaler()\n",
    "        X_tensor = torch.tensor(scaler.fit_transform(X), dtype=torch.float32)\n",
    "        predictions = model(X_tensor)\n",
    "        _, predicted_classes = torch.max(predictions, 1)\n",
    "\n",
    "    return predicted_classes\n",
    "\n",
    "\n",
    "# Generate synthetic data according to established distribution\n",
    "def synthesize_to_distribution(X_df, model, scaler, target_dist, conf_threshold=0.8, n_total=1000):\n",
    "    model.eval()\n",
    "\n",
    "    X_scale = scaler.fit_transform(X_df)\n",
    "    X_tensor = torch.tensor(X_scale, dtype=torch.float32)\n",
    "\n",
    "    # Run through model\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_tensor)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        confs, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    probs_np = probs.numpy()\n",
    "    confs_np = confs.numpy()\n",
    "    preds_np = preds.numpy()\n",
    "\n",
    "    # Filter by confidence\n",
    "    conf_mask = confs_np >= conf_threshold\n",
    "    X_conf = X_df[conf_mask]\n",
    "    probs_conf = probs_np[conf_mask]\n",
    "    confs_conf = confs_np[conf_mask]\n",
    "    preds_conf = preds_np[conf_mask]\n",
    "\n",
    "    class_counts = {\n",
    "        c: int(round(frac * n_total)) for c, frac in target_dist.items()\n",
    "    }\n",
    "\n",
    "    # Select top confident samples\n",
    "    selected_idx = []\n",
    "    for c, count in class_counts.items():\n",
    "        idx_c = np.where(preds_conf == c)[0]\n",
    "        if len(idx_c) == 0:\n",
    "            print(\"something went wrong\")\n",
    "\n",
    "        order = np.argsort(-confs_conf[idx_c])\n",
    "        top_idx = idx_c[order[:count]]\n",
    "        selected_idx.extend(top_idx)\n",
    "    \n",
    "    # Filter out records\n",
    "    X_selected = np.array(X_conf)[selected_idx]\n",
    "    y_selected = preds_conf[selected_idx]\n",
    "    probs_selected = probs_conf[selected_idx]\n",
    "\n",
    "    return X_selected, y_selected, probs_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d22a5110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n",
      "       'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n",
      "       'proanthocyanins', 'color_intensity', 'hue',\n",
      "       'od280/od315_of_diluted_wines', 'proline'],\n",
      "      dtype='object')\n",
      "High-confidence synthetic samples (conf >= .9)\n"
     ]
    }
   ],
   "source": [
    "categorical_features = df.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "continuous_features = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "X_full = df.copy()\n",
    "\n",
    "Xs_synth = synthesize_extrapolated(X_full, continuous_features, categorical_features,\n",
    "                                   n_samples=150, gamma=0.05)\n",
    "\n",
    "print(Xs_synth.columns)\n",
    "\n",
    "y_synth = run_through_model(Xs_synth, model=loaded_model)\n",
    "\n",
    "# probe: how many are high-confidence?\n",
    "print(\"High-confidence synthetic samples (conf >= .9)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "376e7f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "torch.Size([150])\n",
      "Test Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/f11ch57j78xbqrd10jxr7k9r0000gp/T/ipykernel_4678/1579288831.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y_synth, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "X_tensor = torch.tensor(Xs_synth.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_synth, dtype=torch.long)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tensor = torch.tensor(scaler.fit_transform(Xs_synth), dtype=torch.float32)\n",
    "predictions = loaded_model(X_tensor)\n",
    "_, predicted_classes = torch.max(predictions, 1)\n",
    "print(len(predicted_classes))\n",
    "print(y_tensor.shape)\n",
    "accuracy = (predicted_classes == y_tensor).float().mean()\n",
    "print(f\"Test Accuracy: {accuracy.item()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88fe7105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_0  class_1  class_2\n",
      "0     True    False    False\n",
      "1     True    False    False\n",
      "2     True    False    False\n",
      "3    False     True    False\n",
      "4     True    False    False\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "59 71 48\n"
     ]
    }
   ],
   "source": [
    "# Define class names\n",
    "class_names = ['class_0', 'class_1', 'class_2']\n",
    "\n",
    "# One-hot encode\n",
    "ys_onehot = pd.get_dummies(y_synth)\n",
    "ys_onehot.columns = class_names\n",
    "\n",
    "print(ys_onehot.head())\n",
    "\n",
    "s_dataset = pd.concat([Xs_synth, ys_onehot], axis=1)\n",
    "\n",
    "X = df\n",
    "y = data.target\n",
    "print(y)\n",
    "print((y==0).sum(), (y==1).sum(), (y==2).sum())\n",
    "y_oneshot = pd.get_dummies(y)\n",
    "y_oneshot.columns = class_names\n",
    "\n",
    "dataset = pd.concat([X, y_oneshot], axis=1)\n",
    "\n",
    "final_dataset = pd.concat([s_dataset, dataset], ignore_index=True)\n",
    "\n",
    "final_dataset.to_csv(\"wine_synthetic_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6e09e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means of original data:\n",
      " alcohol                          13.000618\n",
      "malic_acid                        2.336348\n",
      "ash                               2.366517\n",
      "alcalinity_of_ash                19.494944\n",
      "magnesium                        99.741573\n",
      "total_phenols                     2.295112\n",
      "flavanoids                        2.029270\n",
      "nonflavanoid_phenols              0.361854\n",
      "proanthocyanins                   1.590899\n",
      "color_intensity                   5.058090\n",
      "hue                               0.957449\n",
      "od280/od315_of_diluted_wines      2.611685\n",
      "proline                         746.893258\n",
      "dtype: float64\n",
      "Means of synthetic data:\n",
      " alcohol                          12.906584\n",
      "malic_acid                        3.120987\n",
      "ash                               2.344812\n",
      "alcalinity_of_ash                19.433797\n",
      "magnesium                       110.391580\n",
      "total_phenols                     2.355541\n",
      "flavanoids                        2.164532\n",
      "nonflavanoid_phenols              0.359864\n",
      "proanthocyanins                   1.734161\n",
      "color_intensity                   6.314493\n",
      "hue                               1.001244\n",
      "od280/od315_of_diluted_wines      2.685462\n",
      "proline                         911.420865\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "means_synthetic = Xs_synth.mean()\n",
    "means_original = df.mean()\n",
    "\n",
    "print(\"Means of original data:\\n\", means_original)\n",
    "print(\"Means of synthetic data:\\n\", means_synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5411d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-confidence synthetic samples (conf >= .9):0.9130295\n"
     ]
    }
   ],
   "source": [
    "### DISTRIBUTION MATCHING\n",
    "\n",
    "num_classes = 3\n",
    "class_names = [0, 1, 2]\n",
    "counts = [59, 71, 48]\n",
    "target_dist = {\n",
    "    class_names[i]: counts[i] / sum(counts) for i in range(num_classes)\n",
    "}\n",
    "\n",
    "\n",
    "num_samples = 150\n",
    "multiplier = 5\n",
    "categorical_features = df.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "continuous_features = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "X_full = df.copy()\n",
    "\n",
    "X_synth_full = synthesize_extrapolated(X_full, continuous_features, categorical_features,\n",
    "                                   n_samples=num_samples * multiplier, gamma=0.05)\n",
    "\n",
    "X_synth, y_synth, probs_synth = synthesize_to_distribution(X_synth_full, loaded_model, StandardScaler(), target_dist, 0.9, num_samples)\n",
    "\n",
    "print(\"High-confidence synthetic samples (conf >= .9):\" + str(np.mean(np.max(probs_synth, axis=1))))\n",
    "\n",
    "\n",
    "# Save data\n",
    "\n",
    "# Define class names\n",
    "class_names = ['class_0', 'class_1', 'class_2']\n",
    "\n",
    "# One-hot encode\n",
    "ys_onehot = pd.get_dummies(y_synth)\n",
    "ys_onehot.columns = class_names\n",
    "\n",
    "X_synth = pd.DataFrame(X_synth, columns=df.columns)\n",
    "\n",
    "s_dataset = pd.concat([X_synth, ys_onehot], axis=1)\n",
    "\n",
    "X = df\n",
    "y = data.target\n",
    "# print(y)\n",
    "# print((y==0).sum(), (y==1).sum(), (y==2).sum())\n",
    "y_oneshot = pd.get_dummies(y)\n",
    "y_oneshot.columns = class_names\n",
    "\n",
    "dataset = pd.concat([X, y_oneshot], axis=1)\n",
    "\n",
    "final_dataset = pd.concat([s_dataset, dataset], ignore_index=True)\n",
    "\n",
    "final_dataset.to_csv(\"wine_synthetic_data.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurorule",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
